{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maagnitude/fetal_health_models/blob/main/fetal_health_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1η Εργασία** στο μάθημα **Μηχανική Μάθηση και Εφαρμογές**\n",
        "\n",
        "# **Τμήμα Πληροφορικής και Τηλεματικής - Χαροκόπειο Πανεπιστήμιο**\n",
        "\n",
        "# **Καζάζης Γεώργιος - it214124**\n",
        "\n",
        "Στην παρούσα εργασία θα αναπτύξουμε **μοντέλα κατηγοριοποίησης**, για να εκτιμήσουμε την υγεία ενός εμβρύου βάσει των χαρακτηριστικών που εξάχθηκαν από εξέταση της εγκύου με καρδιοτοκογράφημα.\n",
        "\n",
        "Πρώτα θα **διερευνήσουμε** τα δεδομένα μας, θα τα **επεξεργαστούμε**, θα **εκπαιδεύσουμε** τα μοντέλα μας και θα **εξετάσουμε** την **αποδοτικότητα** τους.\n",
        "\n",
        "**Αρχίζοντας...**"
      ],
      "metadata": {
        "id": "BZe81lx0eToO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Βιβλιοθήκες**\n",
        "Κάνουμε import τα απαραίτητα **modules**. \n",
        "*   Την **pandas** και την **numpy** για την διαχείρηση των δεδομένων μας.\n",
        "\n",
        "*  Την **matplotlib.pyplot** και την **seaborn** για την οπτικοποίηση των δεδομένων μας. **Ιστογράμματα**, **boxplots** κλπ.\n",
        "\n",
        "*  Την **missingno** ώστε να οπτικοποιήσουμε το αν υπάρχουν ελλιπείς εγγραφές.\n",
        "\n",
        "*   Από την **sklearn** κάνουμε import:\n",
        "      *   Την **linear_model** για να εκπαιδεύσουμε το **Logistic Regression model**.\n",
        "      *   Την **neural_network** για να υλοποιήσουμε και να εκπαιδεύσουμε ΤΝΔ.\n",
        "      *  Την **StardardScaler** και την **train_test_split** για το **Preprocessing** κομμάτι. Συγκεκριμένα για την τυποποίηση των δεδομένων και για να χωρίσουμε τα δεδομένα μας σε **test data** και **train data**.\n",
        "      *  Την **metrics** για τις μετρικές που θα χρησιμοποιήσουμε, όπως η **confusion_matrix**.\n",
        "      *  Την **RandomForestClassifier** για να εκπαιδεύσουμε ένα Random Forest model.\n",
        "*  Το **tensorflow**, και από αυτό, τα **keras** και **layers** για την ανάπτυξη νευρωνικών δικτύων.\n",
        "\n",
        "*  Τέλος, κάνουμε import τα **warnings** και τα φιλτράρουμε, ώστε να μην εμφανίζονται.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fJZqO62JTJPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KSrLlM0SYI0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neural_network\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **read_csv**\n",
        "Περνάμε το **url** του dataset στην μεταβλητή df με την χρήση της μεθόδου read_csv, και εκτυπώνουμε τις 5 πρώτες γραμμές για να δούμε ότι έγιναν όλα σωστά.\n",
        "\n",
        "Το **url** είναι του **raw dataset** απ το repository μου στο **github**."
      ],
      "metadata": {
        "id": "OSxD_cR34Gga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/Maagnitude/fetal_health_models/main/fetal_health.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SrQJdf3B3UOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Table's shape is: \", df.shape[0], \" rows x \", df.shape[1], \" columns.\")"
      ],
      "metadata": {
        "id": "XJDyBsMha_wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Drive mount** (as a second option)\n",
        "Το παρακάτω block κώδικα το έχω κάνει comment γιατί θα ανεβάζω το dataset μέσω του **github url**, από το repository μου. \n",
        "\n",
        "Απλά μέσω του google drive έπαιρνα το dataset, πριν φτιάξω το repository, οπότε το άφησα να υπάρχει σαν επιλογή."
      ],
      "metadata": {
        "id": "dreKl92TUon6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# path = \"/content/drive/MyDrive/Colab Notebooks/fetal_health.csv\"\n",
        "# df = pd.read_csv(path, keep_default_na=False)\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "pm57XOZzSbWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**\n",
        "Παρακάτω θα διερευνήσουμε τα δεδομένα μας."
      ],
      "metadata": {
        "id": "EQTSbfZUkGUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Με την **copy()** δημιουργούμε ένα αντίγραφο της **df** για να το χρησιμοποιήσουμε στην **διερεύνηση των δεδομένων** **(EDA)**, ώστε να μην πειράξουμε το αρχικό **dataframe**."
      ],
      "metadata": {
        "id": "pQ-ebwTvXwFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_df = df.copy()"
      ],
      "metadata": {
        "id": "ZLKj5spXXv2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Info**\n",
        "Με την **info()** τυπώνουμε την συνοπτική περίληψη του dataframe. Συγκεκριμένα τυπώνουμε τον τύπο δεδομένων των στηλών και πόση μνήμη χρησιμοποιείται. Επίσης παρατηρούμε ότι δεν έχουμε missing values, καθώς όλες οι στήλες έχουν **2126** τιμές και είναι **non-null**. Το βλέπουμε και πιο καθαρά με την **isna().sum()** παρακάτω, που αφορά και τις NaN τιμές."
      ],
      "metadata": {
        "id": "jjb9zFWY1uJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_df.info()"
      ],
      "metadata": {
        "id": "C_g6oVm1XVSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eda_df.isna().sum()"
      ],
      "metadata": {
        "id": "ySCLnCH98j40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Δεν υπάρχουν λοιπόν ελλιπείς εγγραφές.**\n",
        "Με την χρήση της συνάρτησης **isnull()** της βιβλιοθήκης **pandas**, θα αποδείξουμε ότι **δεν υπάρχουν ελλιπείς εγγραφές**, δηλαδή ότι έχουμε ένα **πλήρες** σύνολο δεδομένων, όπως είδαμε και πιο πάνω με την **info()** αλλά και το διάγραμμα."
      ],
      "metadata": {
        "id": "s8reBYlPE-dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Are there missing values? \", \"Yes\" if (eda_df.isnull().values.any()) else \"No\")"
      ],
      "metadata": {
        "id": "iRKI6pVEE-V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Οπτική απόδειξη**\n",
        "Με την χρήση της συνάρτησης **bar()** της βιβλιοθήκης **missingno**, βλέπουμε ότι **δεν υπάρχουν** ελλιπείς εγγραφές, καθώς οι μπάρες σε κάθε χαρακτηριστικό φτάνουν στο 1.0"
      ],
      "metadata": {
        "id": "b-nysQwMQL7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_plot = msno.bar(eda_df, color=\"#7600BC\")"
      ],
      "metadata": {
        "id": "ObBx_aWqQLzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ιστόγραμμα**\n",
        "Εδώ τυπώνουμε το **Ιστόγραμμα** κάθε χαρακτηριστικού, με την μέθοδο **hist()**, και τα καταχωρούμε στην μεταβλητή **df_histplot**. Αυτό που μπορούμε να παρατηρήσουμε εδώ είναι ότι το χαρακτηριστικό baseline_value είναι όσο πιο κοντά σε **κανονική κατανομή** σε αντίθεση με τα άλλα χαρακτηριστικά. Στα περισσότερα παρατηρείται **θετική ασυμμετρία**, και σε λίγα (κυρίως **histogram_mode**, **histogram_mean**, **histogram_median**) παρατηρείται **αρνητική ασυμμετρία**, και τα συγκεκριμένα και μεγάλη συσχέτιση μεταξύ τους, όπως θα δούμε και παρακάτω."
      ],
      "metadata": {
        "id": "bb7Kxqsi5Rq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edadf_histplot = eda_df.hist(grid=False, figsize=(25,25), color='#7600BC', zorder=2, rwidth=0.95)"
      ],
      "metadata": {
        "id": "NaqGz4ekayg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Describe**\n",
        "Παρακάτω εμφανίζουμε την στατιστική ανάλυση των δεδομένων μας, με την χρήση της μεθόδου **describe()**. Παρατηρούμε ότι το 75% των δειγμάτων μας ανήκει στην **κατηγορία 1** του fetal_health, δηλαδή 'φυσιολογικό'. Επίσης η στατιστική ανάλυση αφορά και τις 22 στήλες, μιας και έχουμε μόνο αριθμητικά χαρακτηριστικά, κι έτσι θα είναι και πιο εύκολη η επεξεργασία των δεδομένων καθώς και η εκπαίδευση των μοντέλων μας.\n",
        "\n",
        "Σημ: Με **Transpose (.T)** ο πίνακας είναι πιο ευκρινής. Στην αρχή τον είχα αλλιώς, και ήταν κουραστικό."
      ],
      "metadata": {
        "id": "Dw4vA_YM0Vt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_df.describe().T"
      ],
      "metadata": {
        "id": "lMW2N7Gbz_QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Υπολογισμός**\n",
        "Εδώ βλέπουμε πόσες από τις εγγραφές ανήκουν σε κάθε **κατηγορία**, (**normal**, **suspect** ή **pathological**) με χρήση της **value_counts()**"
      ],
      "metadata": {
        "id": "Q7Jp3obVfNH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(eda_df[\"fetal_health\"].value_counts())"
      ],
      "metadata": {
        "id": "HvA42r-xfM7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Category Pie Plot**\n",
        "Εδώ οπτικοποιούμε τα αποτελέσματα του προηγούμενου υπολογισμού, σε ένα διάγραμμα πίτας, βάζοντας και τα ποσοστά, ώστε να δούμε πόσες εγγραφές έχουμε σε κάθε κατηγορία σε σχέση με το σύνολο.\n",
        "Παρατηρούμε ότι έχουμε μεγάλο ποσοστό **Normal**, όπως είδαμε και τον υπολογισμό παραπάνω, που σημαίνει ότι το σύνολο δεδομένων **δεν είναι ισορροπημένο**, μιας και απ τις 3 κατηγορίες (classes) η πρώτη καταλαμβάνει το **77.85%**"
      ],
      "metadata": {
        "id": "kr7ZplbGjLmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.pie(\n",
        "    eda_df['fetal_health'].value_counts(),\n",
        "    labels=[\"Normal\", \"Suspicious\", \"Pathological\"],\n",
        "    autopct='%.2f%%',\n",
        "    colors=sns.color_palette('Purples')\n",
        ")\n",
        "\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show"
      ],
      "metadata": {
        "id": "zqVAkyz2jLdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Boxplot**\n",
        "\n",
        "Ύστερα τυπώνουμε το **boxplot** κάθε χαρακτηριστικού με τη χρήση της συνάρτησης **boxplot()** της βιβλιοθήκης **seaborn**. Παρατηρούμε ότι έχουμε μια σωστή οπτικοποίηση της στατιστικής ανάλυσης που κάναμε παραπάνω μιας και σ ένα θηκόγραμμα μπορούμε να διαβάσουμε 5 τιμές. Τέρμα πάνω έχουμε τη μέγιστη τιμή, και τέρμα κάτω την ελάχιστη. Στην πάνω πλευρά του 'κουτιού' βρίσκεται το 75% των δειγμάτων, στην κάτω πλευρά το 25% και στην γραμμή που βρίσκεται εντός του κουτιού έχουμε το 50%. Πολύ σωστά λοιπόν η γραμμή αυτή στο fetal_health, βρίσκεται πάνω στην τιμή 1, και δεν υπάρχει κουτί μιας και το 75% των δειγμάτων παρουσιάζουν fetal_health ίσο με 1."
      ],
      "metadata": {
        "id": "eMX6G2H7BSOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 15))\n",
        "\n",
        "for i, column in enumerate(eda_df.columns):\n",
        "  plt.subplot(4, 6, i + 1)\n",
        "  sns.boxplot(data=eda_df[column])\n",
        "  plt.title(column)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N3Tn3YJT8BqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ετεροσυσχέτιση**\n",
        "Με την χρήση της συνάρτησης **corr()** της βιβλιοθήκης **pandas**, ελέγχουμε την **ετεροσυσχέτιση** μεταξύ των χαρακτηριστικών. Συγκεκριμένα τυπώνουμε την συσχέτιση όλων των χαρακτηριστικών με το fetal_health, και παρακάτω θα οπτικοποιήσουμε τις συσχετίσεις όλων."
      ],
      "metadata": {
        "id": "QOYdTPTwEfkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = eda_df.corr()\n",
        "corr['fetal_health']"
      ],
      "metadata": {
        "id": "l_w_Vlr9Efb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Heatmap**\n",
        "Εδώ οπτικοποιούμε την **ετεροσυσχέτιση** των χαρακτηριστικών. Αυτή η δισδιάστατη αναπαράσταση μας βοηθάει να καταλάβουμε πολύ πιο εύκολα την ετεροσυσχέτιση, μέσω των χρωμάτων, αλλά και των τιμών. Παρατηρούμε ότι μεγαλύτερη συσχέτιση με το **fetal health** έχει το **prolonged decelerations** (**0.48**)\n",
        "\n",
        "Παρατηρούμε και αυτό που είδαμε πιο πάνω. Ότι τα χαρακτηριστικά histogram_mode, histogram_mean, histogram_median έχουν τεράστια συσχέτιση μεταξύ τους, αλλά πολύ μικρή ετεροσυσχέτιση με το fetal_health (-0.21, -0.23, -0.25), και επειδή ήταν και αυτά που έχουν αρνητική ασσυμετρία, θα δοκιμάσω να τα αφαιρέσω για να δούμε αν το μοντέλο εκπαιδευτεί καλύτερα."
      ],
      "metadata": {
        "id": "tzI21B2NDYpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "heat = sns.heatmap(corr, annot=True, vmin=-1.0, cmap='PuBu')\n",
        "plt.title(\"Correlation Matrix\\n\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UG8iZJWTDYPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.1-2.2 Υλοποίηση συνάρτησης για preprocessing**\n",
        "\n",
        "Εντός αυτής, χωρίζουμε τα δεδομένα σε **train** και **test sets**, μέσω της **train_test_split** με **70% train** και **30% test**, και **random_state 42**. Ύστερα τα κάνουμε scale με τον **StandardScaler()** στα X_train και X_test με αποτέλεσμα οι τιμές κάθε χαρακτηριστικού να τυποποιούνται με κέντρο 0 και τυπική απόκλιση 1."
      ],
      "metadata": {
        "id": "dsRJEA8_R2z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_func(fitdf):\n",
        "\n",
        "  # Χωρίζουμε το fitdf σε X (features) και y (labels)\n",
        "  y = fitdf['fetal_health']\n",
        "  X = fitdf.drop('fetal_health', axis=1)\n",
        "\n",
        "  # Χωρίζουμε τα X και y σε train και test set (70%-30%) με random_state=42\n",
        "  X_train, X_test, y_train, y_test = \\\n",
        "  train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "  # Τυποποιούμε τα X_train και X_test\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "  X_train_std = scaler.transform(X_train)\n",
        "  X_test_std = scaler.transform(X_test)\n",
        "\n",
        "  return X_train_std, X_test_std, y_train, y_test"
      ],
      "metadata": {
        "id": "NsllJiO_g-5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.3.1 Υλοποίηση συνάρτησης για την εκπαίδευση γραμμικού μοντέλου**\n",
        "\n",
        "Θα την χρησιμοποιήσουμε δίνοντας της τα χωρισμένα **train** και **test sets**, ώστε να εκπαιδευτεί (**fit**) στα train και ύστερα να εξεταστεί (**metrics.accuracy_score**) στο test, σύμφωνα με τα label που πρόβλεψε (**y_hat_test**), ώστε να πάρουμε το **accuracy**. Με την **predict** θα πάρουμε όλες τις τιμές που πρόβλεψε ώστε να φτιάξουμε τον **confusion matrix**. \n",
        "\n",
        "Στο μοντέλο αφήσαμε το **default penalty** (**l2**) και απλά βάλαμε την παράμεντρο **C=0.1** με την οποία παρατηρήθηκε αύξηση στο accuracy."
      ],
      "metadata": {
        "id": "XhbH91d3X_k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_linear_sklearn(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  # Εκπαίδευση μοντέλου\n",
        "  lr = linear_model.LogisticRegression(C=0.1)\n",
        "  model = lr.fit(X_train, y_train)\n",
        "\n",
        "  # Τεστάρισμα μοντέλου\n",
        "  y_hat_test = model.predict(X_test)\n",
        "  accuracy = round(metrics.accuracy_score(y_test, y_hat_test), 3)\n",
        "\n",
        "  # Υπολογισμός του confusion matrix\n",
        "  confmatrix = confusion_matrix(y_test, y_hat_test)\n",
        "\n",
        "  return accuracy, confmatrix"
      ],
      "metadata": {
        "id": "tD0S1foJMkQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Υλοποίηση συνάρτησης για τον σχεδιασμό του Confusion Matrix**\n",
        "\n",
        "Με χρήση ενός heatmap θα παρουσιάσουμε τα αποτελέσματα του υπολογισμένου confusion matrix, όπου βάζουμε τις παραμέτρους annot=True και annot_kws={'size':20} για να εμφανίσουμε τις τιμές σε κάθε περιοχή του πίνακα, και να έχουν μέγεθος 20. Επίσης, η παράμετρος **fmt=\"d\"** είναι για να εμφανίζονται οι τιμές ως ακέραιοι. (Γιατί χωρίς αυτήν, το 466 εμφανιζόταν ως 4.7e+02)\n",
        "\n",
        "Τέλος, με την **axis.tick_top()** βάζουμε τα labels του άξονα x στην κορυφή του plot."
      ],
      "metadata": {
        "id": "iEj_LbjR61Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heat_confmatrix (confmatrix):\n",
        "  \n",
        "  labels = ['Normal', 'Suspicious', 'Pathological']\n",
        "\n",
        "  # Δίνουμε τα labels στον πίνακα\n",
        "  conf_matr_plt = pd.DataFrame(confmatrix, index = labels, columns = labels)\n",
        "  \n",
        "  plt.subplots(figsize=(7, 5))\n",
        "  \n",
        "  ax = sns.heatmap(conf_matr_plt, cmap='viridis', annot=True, annot_kws={'size':20}, fmt=\"d\")\n",
        "\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.set_title(\"Confusion Matrix\\n\")\n",
        "  plt.ylabel('True')\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nz652KHG604J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Δημιουργία αντίγραφου του Dataframe μας**\n",
        "\n",
        "Πρώτα αφαιρούμε 1 από κάθε label ώστε να μειώσουμε το σύνολο τιμών και να τις κάνουμε να ξεκινάνε απ το 0, ώστε να μην έχουμε πρόβλημα στο one-hot encoding και τον υπολογισμό του confusion matrix (μιας και πριν συμπλήρωνε μία γραμμή και στήλη με μηδενικά).\n",
        "\n",
        "Ύστερα φτιάχνουμε το **fitdf**, ώστε να μην πειράξουμε το αρχικό dataframe μας. Όλες οι αλλαγές θα γίνουν πάνω σ αυτό."
      ],
      "metadata": {
        "id": "HGZZ6g4HZsd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels (1, 2, 3) --> (0, 1, 2) \n",
        "df['fetal_health'] -= 1\n",
        "# Να μην εκτελεστεί πάνω από μία φορά. Αν εκτελεστεί, δεν πρέπει να τρέξουμε πάλι\n",
        "# την εντολή από κάτω, γιατί το αντίγραφο θα έχει αρνητικές τιμές, μιας και το ένα\n",
        "# label, από 0 θα γίνει -1."
      ],
      "metadata": {
        "id": "S5k0AdK5_soD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitdf = df.copy()"
      ],
      "metadata": {
        "id": "ruFRVDRFLGBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitdf.head()"
      ],
      "metadata": {
        "id": "44ARE3IvPhtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Τώρα θα τρέξουμε τις συναρτήσεις που υλοποιήσαμε για το **standarization** και **split** των datasets, καθώς και το **fit** και **predict** του μοντέλου."
      ],
      "metadata": {
        "id": "-76_7ABidHrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = preprocessing_func(fitdf)"
      ],
      "metadata": {
        "id": "YmRUNe70iotr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, confmatrix = run_linear_sklearn(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "tCXIMwp-V7GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accuracy: 0.895**\n",
        "\n",
        "Αρχικά είχα εκπαιδεύσει και ένα μοντέλο, **χωρίς** την χρήση του StandardScaler και της παραμέτρου C=0.1, για δοκιμή και είχε **accuracy 0.85** (Το κομμάτι αφαιρέθηκε για να μειωθεί η έκταση του notebook)\n",
        "\n",
        "Εδώ το accuracy είναι **0.895** και θα προσπαθήσουμε να το αυξήσουμε λίγο."
      ],
      "metadata": {
        "id": "kOZHJobsdXBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model's accuracy: {accuracy:.4f}\\n\")\n",
        "heat_confmatrix(confmatrix)"
      ],
      "metadata": {
        "id": "4MTz9Kr1cQOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Παρατηρήσεις πάνω στο Confusion Matrix**\n",
        "\n",
        "Μόνο σ αυτό το confusion matrix θα αναλύσουμε τι παρατηρούμε.\n",
        "\n",
        "* Όταν το μοντέλο προέβλεψε **normal**, τα 472 ήταν όντως normal, τα 28 όμως ήταν suspicious και τα υπόλοιπα 4 ήταν pathological.\n",
        "\n",
        "* Όταν προέβλεψε **suspicious**, τα 66 ήταν όντως suspicious,όμως τα 20 ήταν normal και τα υπόλοιπα 4 pathological.\n",
        "\n",
        "* Όταν προέβλεψε **pathological**, τα 33 ήταν όντως pathological, όμως τα 4 ήταν normal και τα υπόλοιπα 7 ήταν suspicious.\n",
        "\n",
        "Συνολικά έπεσε μέσα σε 472 + 66 + 33 = **571** προβλέψεις, από τις συνολικές **638**, δίνοντας μας το accuracy 571 / 638 = **89.5%**\n",
        "\n"
      ],
      "metadata": {
        "id": "_wtzSnH0QLEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Τώρα μια δοκιμή**"
      ],
      "metadata": {
        "id": "Edoqoit2FY6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Αν θεωρήσουμε τους '**ύποπτους για παθολογία**' και τους '**παθολογικούς**' ως μία κατηγορία, μειώνοντας τις κλάσεις μας σε 2, τότε με τον παρακάτω κώδικα κάνουμε το χαρακτηριστικό αυτό να είναι ή 0 ή 1, με χρήση ενός **list comprehension**."
      ],
      "metadata": {
        "id": "i2oplUVmdk1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fitdf['fetal_health'].value_counts()"
      ],
      "metadata": {
        "id": "U31jczObQDhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitdf['fetal_health'] = [1 if x == 2.0 or x == 1.0 else 0 for x in fitdf['fetal_health']]\n",
        "fitdf['fetal_health'].value_counts()"
      ],
      "metadata": {
        "id": "yqk6A4opGA6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Όπως βλέπουμε παραπάνω, οι τιμές μοιράστηκαν. Έτσι το σύνολο δεδομένων μας είναι **λίγο** περισσότερο ισορροπημένο."
      ],
      "metadata": {
        "id": "qJ5VApZ6eYiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accuracy: 0.909 αλλά...**"
      ],
      "metadata": {
        "id": "HrlXILk-gKtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = preprocessing_func(fitdf)\n",
        "accuracy, confmatrix = run_linear_sklearn(X_train, X_test, y_train, y_test)\n",
        "print(f\"Model's accuracy after merging: {accuracy:.4f}\\n\")\n",
        "print(f'Confusion matrix after merging:\\n {confmatrix}')"
      ],
      "metadata": {
        "id": "ARHLiX53eoMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ίσως δεν είναι απόλυτα σωστό να ενώσουμε τις δύο κατηγορίες (2 και 3) και δεν μας αύξησαν και ιδιαίτερα το accuracy (ιδίως απ τη στιγμή που δεν βρίσκουν καν ακριβώς αυτό που θέλουμε), οπότε θα ξεκινήσουμε πάλι με αντίγραφο του αρχικού dataset και θα επεξεργαστούμε λίγο τα δεδομένα μας, ώστε να πετύχουμε κάτι πάνω απ το 0.909 που πετύχαμε ακριβώς από πάνω."
      ],
      "metadata": {
        "id": "gKAsKJR7gewa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Μια δεύτερη δοκιμή**\n",
        "Αυτό που θα μας ανεβάσει κι άλλο το **accuracy** θα είναι να πετάξουμε τυχόν **διπλότυπα**, μιας και αυτά είναι περιττά για την εκπαίδευση και το μόνο που πετυχαίνουν είναι να **υπερεκπαιδεύσουν** το μοντέλο μας.\n",
        "\n",
        "Επίσης θα δοκιμάσουμε να αφαιρέσουμε και τα χαρακτηριστικά **histogram_mean**, **histogram_mode** και **histogram_median** όπως αναφέραμε πιο πάνω."
      ],
      "metadata": {
        "id": "8awYhsgMi5FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fitdf = df.copy()"
      ],
      "metadata": {
        "id": "mNNVMiwJsHlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitdf.shape"
      ],
      "metadata": {
        "id": "QkCU27JhjePR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_df = fitdf.drop(['histogram_mean', 'histogram_mode', 'histogram_median'], axis = 1)\n",
        "final_df = fitdf.drop_duplicates()\n",
        "final_df.shape"
      ],
      "metadata": {
        "id": "cZz-iiBWsMD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accuracy: 0.9180**\n",
        "Παρατηρούμε ότι αφαιρώντας **13 διπλότυπα δείγματα**, το accuracy ανέβηκε στο **0.9180**, το οποίο είναι ικανοποιητικό. (Το τελικό dataframe το βάλαμε στο **final_df**.)\n",
        "\n",
        "Αφαιρώντας τα τρία χαρακτηριστικά που ανέφερα πήγε στο 0.9200, αλλά αποφάσισα να μην το κάνω έτσι οπότε θα τα κρατήσουμε, κι ας είναι μικρότερο το accuracy. Έτσι κι αλλιώς το 0.02 δεν είναι και σημαντική βελτίωση."
      ],
      "metadata": {
        "id": "4oTgfX3Mjjk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = preprocessing_func(final_df)\n",
        "accuracy, confmatrix = run_linear_sklearn(X_train, X_test, y_train, y_test)\n",
        "print(f\"Model's accuracy after merging and dupl_dropping: {accuracy:.4f}\\n\")\n",
        "heat_confmatrix(confmatrix)"
      ],
      "metadata": {
        "id": "9aewWTZfUL90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.3.2 Tensorflow**\n",
        "Δημιουργία συνάρτησης για την εκπαιδεύση νέου γραμμικού μοντέλου με tensorflow.\n",
        "\n",
        "Το φτιάξαμε με ένα layer, το οποίο έχει 3 νευρώνες και δέχεται ένας διάνυσμα 21 χαρακτηριστικών (**X_train.shape[1],**). Θα έχουμε 3 εξόδους (μία για κάθε label, από κάθε νευρώνα) και οι τιμές τους θα αθροίζουν στο 1, λόγω του ότι έχει activation function την **softmax**. (δηλ. ποσοστό σιγουριάς του μοντέλου για το ποιο label είναι πιθανότερο να είναι σωστό)\n",
        "\n",
        "Στο μοντέλο χρησιμοποιούμε **sparse_categorical_crossentropy** γιατί δεν έχουμε κάνει **one-hot encoding** στα labels και τα έχουμε σαν **integers**. (Αν βάζαμε ή **relu** ή **sigmoid** δεν θα ήταν πλέον γραμμικό το μοντέλο.)\n",
        "\n",
        "Επίσης χρησιμοποιούμε **SGD optimizer** με προεπιλεγμένο **batch size** και **learning rate**, και το εκπαιδεύουμε για 50 εποχές."
      ],
      "metadata": {
        "id": "7KsYAVP4kz6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_linear_tf(X_train, X_test, y_train, y_test):\n",
        "  \n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(3, activation='softmax', input_shape=(X_train.shape[1],))\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.SGD(),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  model.summary()\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=50)\n",
        "  accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "  y_test_c = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  pred_idx = np.argmax(y_pred, axis=1)\n",
        "  true_idx = np.argmax(y_test_c, axis=1)\n",
        "  tf_confmatrix = tf.math.confusion_matrix(true_idx, pred_idx, num_classes=3)\n",
        "\n",
        "  return accuracy, tf_confmatrix"
      ],
      "metadata": {
        "id": "Fcr8eazXDG-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, tf_confmatrix = run_linear_tf(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "x0jnT-516Ria"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Με το απλό αυτό γραμμικό μοντέλο έχουμε **accuracy 0.90**\n",
        "\n",
        "Παρόλο που κατά την αύξηση του σε κάθε εποχή, έφτασε το **~0.885** με loss **~0.29** (στην **50η εποχή**), στο **test set** πέτυχε **~0.90** με loss **~0.25**\n",
        "\n",
        "Δηλαδή σε κάθε φορά που το έτρεξα, στο test set πέτυχε καλύτερα αποτελέσματα."
      ],
      "metadata": {
        "id": "kpkr9BCWUo0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test loss: {accuracy[0]:.4f}')\n",
        "print(f'Test accuracy: {accuracy[1]:.4f}')"
      ],
      "metadata": {
        "id": "z7eX-WRdvjTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Κάνουμε plot σε heatmap το νέο confusion matrix.**\n",
        "\n",
        "Σημ: Βρήκα μετά από αρκετό ψάξιμο, ότι για να το κάνουμε plot χρειάζεται η συνάρτηση **numpy()**, γιατί αλλιώς μου έβγαζε το σφάλμα \"**Cannot convert 3.0 to EagerTensor of dtype int32**\""
      ],
      "metadata": {
        "id": "MSGGSEqSD2Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heat_confmatrix(tf_confmatrix.numpy())"
      ],
      "metadata": {
        "id": "XLWlnI2TSCgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Και τώρα θα δοκιμάσουμε στα αρχικά δεδομένα (πριν την τυποποίηση) για να συγκρίνουμε."
      ],
      "metadata": {
        "id": "WlvMWhGlb2G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig_df = df.copy()"
      ],
      "metadata": {
        "id": "CwZ6uE76ek0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_without_standard(orig_df):\n",
        "  \n",
        "  # Χωρίζουμε το fitdf σε X (features) και y (labels)\n",
        "  y = orig_df['fetal_health']\n",
        "  X = orig_df.drop('fetal_health', axis=1)\n",
        "\n",
        "  # Χωρίζουμε τα X και y σε train και test set (70%-30%) με random_state=42\n",
        "  X_train, X_test, y_train, y_test = \\\n",
        "  train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "8NhBPDRBePE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = run_without_standard(orig_df)\n",
        "accuracy, tf_confmatrix = run_linear_tf(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "Ym3M1KNfbx2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Παρατηρούμε λοιπόν, ότι το accuracy ανεβοκατέβαινε συνεχώς, κατά την διάρκεια της εκπαίδευσης, σε τιμές γύρω απ το 0.80, σαν να μην υπήρχε βελτίωση σε κάθε εποχή και το αποτέλεσμα είναι απρόβλεπτο. Το τελικό test_accuracy ήταν 0.807 τη μία φορά, 0.70 την άλλη.\n",
        "\n",
        "Επίσης το test loss ηταν πολύ μεγάλο και απρόβλεπτο επίσης (ανεβοκατέβαινε κι αυτό). Το τελικό test loss, τη μία ήταν 24 και την άλλη 137."
      ],
      "metadata": {
        "id": "pnDcsMvzcfIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test loss: {accuracy[0]:.4f}')\n",
        "print(f'Test accuracy: {accuracy[1]:.4f}')"
      ],
      "metadata": {
        "id": "oQpl0ecpcRzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Έτσι και το confusion matrix έχει απρόβλεπτη συμπεριφορά. Τις περισσότερες φορές που το έτρεξα είχε μηδενικές τιμές σε όλη τη στήλη του suspicious predicted."
      ],
      "metadata": {
        "id": "dYX3Ixi8hp0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heat_confmatrix(tf_confmatrix.numpy())"
      ],
      "metadata": {
        "id": "tLdD031WfSxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.4 Πειραματισμός για ανάπτυξη μοντέλου νευρωνικού δικτύου**\n",
        "\n",
        "Παρακάτω υπάρχει ένας πίνακας με τους 'πειραματισμούς' που έκανα. Δυστυχώς δεν έκανα πολλά πράγματα, αλλά γενικά παρατηρούμε ότι όσα περισσότερα έβαζα (**>3 hidden layers**, **>100 neurons**, πήγαινε σχετικά **χειρότερα** η εκπαίδευση. \n",
        "\n",
        "Το μεγαλύτερο accuracy (**0.9527**), εμφανίστηκε στην τελευταία γραμμή του πίνακα, με **2 hidden layer**, **100 neurons** το καθένα, **Adam optimizer**, **learning rate schedule** (**0.01-0.001-0.0001**), **100 εποχές** και **batch size 128**.\n",
        "\n",
        "Αυτό συμβαίνει όπως λέει και η **εκφώνηση** επειδή ένα σύνθετο νευρωνικό δίκτυο εύκολα **υπερεκπαιδεύεται** και δεν πετυχαίνει καλά αποτελέσματα σε ένα σχετικά μικρό σύνολο δεδομένων.\n",
        "\n",
        "Σημ: Ο scheduler φτιάχτηκε σαν callback γιατί μου φάνηκε πιο εύκολο όταν το έψαξα και το βρήκα έτσι. Δεν ξέρω αν είναι απόλυτα σωστό."
      ],
      "metadata": {
        "id": "7AzVvwfsVbpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = preprocessing_func(final_df)"
      ],
      "metadata": {
        "id": "RczW6MkfVbIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experimodel(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      layers.Input(shape=(X_train.shape[1],), name='input'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(3, activation='softmax', name='output')      \n",
        "  ])\n",
        "\n",
        "  def lr_schedule(epoch):\n",
        "    if epoch < 60:\n",
        "      return 0.01\n",
        "    elif epoch < 80:\n",
        "      return 0.001\n",
        "    else:\n",
        "      return 0.0001\n",
        "\n",
        "  lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  model.summary()\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=100, batch_size = 128, callbacks=[lr_scheduler])\n",
        "  accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "  y_test_c = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  pred_idx = np.argmax(y_pred, axis=1)\n",
        "  true_idx = np.argmax(y_test_c, axis=1)\n",
        "  exp_confmatrix = tf.math.confusion_matrix(true_idx, pred_idx)\n",
        "\n",
        "  return accuracy, exp_confmatrix"
      ],
      "metadata": {
        "id": "PxYigHO9celF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, exp_confmatrix = experimodel(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "_leIGfsHcehx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test loss: {accuracy[0]:.4f}')\n",
        "print(f'Test accuracy: {accuracy[1]:.4f}\\n')\n",
        "heat_confmatrix(tf_confmatrix.numpy())"
      ],
      "metadata": {
        "id": "GsLwe4sXfhb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Hid. Layers', 'Neurons', 'Ativation', 'Optimizer',\n",
        "          'Learn. Rate', 'Epochs', 'Batch size', 'Accuracy', 'Loss']\n",
        "\n",
        "data = [['2', '100', 'relu', 'Adam', '0.001', '50', '128', '0.9385', '0.1726'],\n",
        "        ['3', '100', 'relu',  'SGD', '0.001','100',  '32', '0.8817', '0.3595'],\n",
        "        ['3', '150', 'relu',  'SGD', '0.001', '50', '128', '0.7839', '0.6920'],\n",
        "        ['2', '150', 'relu', 'Adam', '0.001', '50', '128', '0.9401', '0.1898'],\n",
        "        ['4', '150', 'relu',  'SGD',  '0.01','100',  '32', '0.9354', '0.1890'],\n",
        "        ['5', '150', 'relu',  'SGD',  '0.01','100',  '32', '0.9338', '0.2360'],\n",
        "        ['4', '150', 'relu', 'Adam', '0.001','100',  '32', '0.9306', '0.2530'],\n",
        "        ['4', '150', 'relu', 'Adam', '0.001','100',  '64', '0.9385', '0.4958'],\n",
        "        ['3', '150', 'relu', 'Adam', '0.01', '100',  '64', '0.8824', '0.3369'],\n",
        "        ['3', '200', 'relu', 'Adam', '0.01-0.0001','100',  'def', '0.8903', '0.3127'],\n",
        "        ['6', '150', 'relu', 'Adam', '0.01-0.0001','100',  '128', '0.8903', '0.2902'],\n",
        "        ['2', '100', 'relu', 'Adam', '0.01-0.0001','100',  '128', '0.9527', '0.2804']]\n",
        "\n",
        "data = np.array(data)\n",
        "fig, ax = plt.subplots()\n",
        "table = ax.table(cellText=data, colLabels=labels, loc='center')\n",
        "table.set_fontsize(20)\n",
        "table.scale(5,7)\n",
        "ax.axis('off')\n",
        "ax.grid(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4oE65LhYfV9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.5 Σχεδιασμός αρχιτεκτονικής νευρωνικού δικτύου**\n",
        "\n",
        "Δημιουργούμε ένα **ΤΝΔ** με **4 κρυφά επίπεδα 100 νευρώνων**, με συνάρτηση ενεργοποίησης **ReLU**, **Adam optimizer** με **ρυθμό εκμάθησης 0.001** και **100 εποχές εκπαίδευσης**.\n",
        "\n",
        "Θα δούμε πως πετυχαίνει **χαμηλότερο accuraty** και **υψηλότερο loss** από το νευρωνικό που υλοποιήσαμε πιο πάνω, επειδή έχει 2 hidden layers παραπάνω, και σταθερό learning rate."
      ],
      "metadata": {
        "id": "7KgYdqucKDk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tf_NN(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      layers.Input(shape=(X_train.shape[1],), name='input'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(3, activation='softmax', name='output')      \n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  model.summary()\n",
        "  history = model.fit(X_train, y_train, epochs=100, batch_size = 128)\n",
        "  accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "  y_test_c = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  pred_idx = np.argmax(y_pred, axis=1)\n",
        "  true_idx = np.argmax(y_test_c, axis=1)\n",
        "  tf_confmatrix = tf.math.confusion_matrix(true_idx, pred_idx)\n",
        "\n",
        "  return accuracy, tf_confmatrix"
      ],
      "metadata": {
        "id": "d295NJtnkzun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, tf_confmatrix = run_tf_NN(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "mg7hL8fzJPKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model evaluation on test set**\n",
        "Το μοντέλο μας σημειώνει ένα πολύ ικανοποιητικό **accuracy** στο **test set   ~94.5%**"
      ],
      "metadata": {
        "id": "yLBSJELqUrpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test loss: {accuracy[0]:.4f}')\n",
        "print(f'Test accuracy: {accuracy[1]:.4f}\\n')\n",
        "heat_confmatrix(tf_confmatrix.numpy())"
      ],
      "metadata": {
        "id": "LqMCmEtkTNKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.6 Random Forest Classification**\n",
        "\n",
        "Με τη χρήση του μοντέλου **Random Forest** πετυχαίνουμε **accuracy ~0.960**\n",
        "\n",
        "Είναι αρκετά καλύτερο απ τα γραμμικά μοντέλα που χρησιμοποιήσαμε προηγουμένως, με την έννοια ότι εμφάνισε καλύτερο accuracy και η εκπαίδευση του έγινε υπερβολικά πιο γρήγορα, σε αντίθεση με τα μοντέλα νευρωνικών δικτύων που εκπαιδεύσαμε πιο πάνω. Παρατηρούμε λοιπόν ότι το **Random Forest** είναι πιο αποδοτικό σε προβλήματα **κατηγοριοποίησης**, ειδικά τώρα που έχουμε μόνο **2113 δείγματα**.\n",
        "\n",
        "Σημ: Με μόνο 5 γραμμές κώδικα."
      ],
      "metadata": {
        "id": "luwULq9SVH9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "accuracy = model.score(X_test, y_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "confmatrix = confusion_matrix(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}\\n')\n",
        "heat_confmatrix(confmatrix)"
      ],
      "metadata": {
        "id": "WbQopjxDVf75"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}